#For final model predictions go ahead and refit lasso using entire
#data set
finalmodel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)
# LASSO chose : age, workclass, fnlwgt, education, marital.status, occupation, relationship, race,
# hours.per.week, native.country, capgain, caploss
mod.lasso <- glm(Income~age + workclass + fnlwgt + education +
marital.status + occupation + relationship +
race + hours.per.week + native.country + capgain + caploss,
data=train, family = "binomial")
pred.lasso <- predict(mod.lasso, newdata = test, type = "response")
summary(mod.lasso)
car::vif(mod.lasso)
exp(cbind("Odds ratio" = coef(mod.lasso), confint.default(mod.lasso, level = 0.95)))
par(mfrow=c(2,2))
plot(mod.lasso)
# something going on with observation 3316 has leverage of one
# function to identify high leverage obs and we want to make sure the row is 3316 and not the row.names
# https://towardsdatascience.com/how-to-detect-unusual-observations-on-your-regression-model-with-r-de0eaa38bc5b
par(mfrow=c(1,1))
highleverage <- function(mod.lasso) {
p <- length(coefficients(mod.lasso))
n <- length(fitted(mod.lasso))
ratio <-p/n
base::plot(hatvalues(mod.lasso), main="Index Plot of Ratio")
abline(h=c(2,3)*ratio, col="red", lty=2)
identify(1:n, hatvalues(mod.lasso), names(hatvalues(mod.lasso)))
}
highleverage(mod.lasso)
# again we see 3316 has very high ratio of coefficients to fitted values and the row is 3316 with the row name = "19610"
mod.lasso <- glm(Income~age + fnlwgt + education +
marital.status + occupation + relationship +
race + hours.per.week + native.country + capgain + caploss,
data=train, family = "binomial")
pred.lasso <- predict(mod.lasso, newdata = test, type = "response")
summary(mod.lasso)
car::vif(mod.lasso)
exp(cbind("Odds ratio" = coef(mod.lasso), confint.default(mod.lasso, level = 0.95)))
par(mfrow=c(2,2))
plot(mod.lasso)
# something going on with observation 3316 has leverage of one
# function to identify high leverage obs and we want to make sure the row is 3316 and not the row.names
# https://towardsdatascience.com/how-to-detect-unusual-observations-on-your-regression-model-with-r-de0eaa38bc5b
#Lets use the predicted probabilities to classify the observations and make a final confusion matrix for the two models.  We can use it to calculate error metrics.
#Lets use a cutoff of 0.7 to make the classification.
# factor level order (0,1) = (<=50K, >50K)
cutoff.lasso <- 0.265
cutoff.step <- 0.265
class.lasso <- factor(ifelse(pred.lasso>cutoff.lasso,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step <- factor(ifelse(pred.step>cutoff.step,">50K","<=50K"),levels=c("<=50K",">50K"))
#Confusion Matrix for Lasso
conf.lasso <- table(class.lasso, test$Income)
print("Confusion matrix for LASSO")
conf.lasso
conf.step<-table(class.step,test$Income)
print("Confusion matrix for Stepwise")
conf.step
#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step <- sum(diag(conf.step))/sum(conf.step)
print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step
# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step <- sensitivity(conf.step)
# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step <- specificity(conf.step)
results.lasso <- prediction(pred.lasso, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso <- performance(results.lasso, measure = "tpr", x.measure = "fpr")
results.step <- prediction(pred.step, test$Income, label.ordering=c("<=50K",">50K"))
roc.step <- performance(results.step, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(roc.lasso, col = "red")
plot(roc.step,col="green", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise"),
col=c("black","green"),lty=1,lwd=1)
abline(a=0, b= 1)
# generate AUC values
auc.lasso <- performance(results.lasso, measure = "auc")
auc.step <- performance(results.step, measure = "auc")
auc.lasso@y.values[[1]]
auc.step@y.values[[1]]
# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso, cutoff.step)
sens <- c(sens.lasso, sens.step)
spec <- c(spec.lasso, spec.step)
acc <- c(acc.lasso, acc.step)
auc <- c(auc.lasso@y.values[[1]], auc.step@y.values[[1]])
testResults <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults) <- c("LASSO", "Stepwise")
#write.csv(testResults, "testResults.csv")
testResults
# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso, cutoff.step)
sens <- c(sens.lasso, sens.step)
spec <- c(spec.lasso, spec.step)
acc <- c(acc.lasso, acc.step)
auc <- c(auc.lasso@y.values[[1]], auc.step@y.values[[1]])
testResults <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults) <- c("LASSO", "Stepwise")
#write.csv(testResults, "testResults.csv")
testResults
#Lets use the predicted probabilities to classify the observations and make a final confusion matrix for the two models.  We can use it to calculate error metrics.
#Lets use a cutoff of 0.7 to make the classification.
# factor level order (0,1) = (<=50K, >50K)
cutoff.lasso <- 0.265
cutoff.step <- 0.265
class.lasso <- factor(ifelse(pred.lasso>cutoff.lasso,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step <- factor(ifelse(pred.step>cutoff.step,">50K","<=50K"),levels=c("<=50K",">50K"))
#Confusion Matrix for Lasso
conf.lasso <- table(class.lasso, test$Income)
print("Confusion matrix for LASSO")
conf.lasso
conf.step<-table(class.step,test$Income)
print("Confusion matrix for Stepwise")
conf.step
#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step <- sum(diag(conf.step))/sum(conf.step)
print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step
# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step <- sensitivity(conf.step)
# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step <- specificity(conf.step)
results.lasso <- prediction(pred.lasso, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso <- performance(results.lasso, measure = "tpr", x.measure = "fpr")
results.step <- prediction(pred.step, test$Income, label.ordering=c("<=50K",">50K"))
roc.step <- performance(results.step, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(roc.lasso, col = "red")
plot(roc.step,col="green", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise"),
col=c("black","green"),lty=1,lwd=1)
abline(a=0, b= 1)
# generate AUC values
auc.lasso <- performance(results.lasso, measure = "auc")
auc.step <- performance(results.step, measure = "auc")
auc.lasso@y.values[[1]]
auc.step@y.values[[1]]
# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso, cutoff.step)
sens <- c(sens.lasso, sens.step)
spec <- c(spec.lasso, spec.step)
acc <- c(acc.lasso, acc.step)
auc <- c(auc.lasso@y.values[[1]], auc.step@y.values[[1]])
testResults <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults) <- c("LASSO", "Stepwise")
#write.csv(testResults, "testResults.csv")
testResults
# using the MASS package
mod.full <- glm(Income~., data=train, family = "binomial")
mod.step <- mod.full %>% stepAIC(trace=FALSE)
pred.step <- predict(mod.step, newdata = test, type = "response")
summary(mod.step)
car::vif(mod.step)
exp(cbind("Odds ratio" = coef(mod.step), confint.default(mod.step, level = 0.95)))
par(mfrow=c(2,2))
plot(mod.step)
holder <- clean
set.seed(123)
# establish the orde of the Income factor levels
smp.size <- floor( (nrow(clean)/3) * 2)
train.ind <- sample(seq_len(nrow(clean)), size=smp.size)
train <- clean[train.ind,]
test <- clean[-train.ind,]
prop.table(table(train$Income))
# ~76% <=50K
# ~ 24% >50K
# using the MASS package
mod.full <- glm(Income~., data=train, family = "binomial")
mod.step <- mod.full %>% stepAIC(trace=FALSE)
pred.step <- predict(mod.step, newdata = test, type = "response")
summary(mod.step)
car::vif(mod.step)
exp(cbind("Odds ratio" = coef(mod.step), confint.default(mod.step, level = 0.95)))
par(mfrow=c(2,2))
plot(mod.step)
warnings()
#Lets use the predicted probabilities to classify the observations and make a final confusion matrix for the two models.  We can use it to calculate error metrics.
#Lets use a cutoff of 0.7 to make the classification.
# factor level order (0,1) = (<=50K, >50K)
cutoff.lasso <- 0.265
cutoff.step <- 0.265
class.lasso <- factor(ifelse(pred.lasso>cutoff.lasso,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step <- factor(ifelse(pred.step>cutoff.step,">50K","<=50K"),levels=c("<=50K",">50K"))
#Confusion Matrix for Lasso
conf.lasso <- table(class.lasso, test$Income)
print("Confusion matrix for LASSO")
conf.lasso
conf.step<-table(class.step,test$Income)
print("Confusion matrix for Stepwise")
conf.step
#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step <- sum(diag(conf.step))/sum(conf.step)
print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step
# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step <- sensitivity(conf.step)
# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step <- specificity(conf.step)
results.lasso <- prediction(pred.lasso, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso <- performance(results.lasso, measure = "tpr", x.measure = "fpr")
results.step <- prediction(pred.step, test$Income, label.ordering=c("<=50K",">50K"))
roc.step <- performance(results.step, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(roc.lasso, col = "red")
plot(roc.step,col="green", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise"),
col=c("black","green"),lty=1,lwd=1)
abline(a=0, b= 1)
# generate AUC values
auc.lasso <- performance(results.lasso, measure = "auc")
auc.step <- performance(results.step, measure = "auc")
auc.lasso@y.values[[1]]
auc.step@y.values[[1]]
# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso, cutoff.step)
sens <- c(sens.lasso, sens.step)
spec <- c(spec.lasso, spec.step)
acc <- c(acc.lasso, acc.step)
auc <- c(auc.lasso@y.values[[1]], auc.step@y.values[[1]])
testResults <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults) <- c("LASSO", "Stepwise")
#write.csv(testResults, "testResults.csv")
testResults
summary(mod.lasso)
exp(cbind("Odds ratio" = coef(mod.lasso), confint.default(mod.lasso, level = 0.95)))
levels(train$workclass)
levels(train$education)
summary(mod.step)
car::vif(mod.step)
car::vif(mod.lasso)
par(mfrow=c(2,2))
plot(mod.step)
#Lets use the predicted probabilities to classify the observations and make a final confusion matrix for the two models.  We can use it to calculate error metrics.
#Lets use a cutoff of 0.7 to make the classification.
# factor level order (0,1) = (<=50K, >50K)
cutoff.lasso <- 0.265
cutoff.step <- 0.265
class.lasso <- factor(ifelse(pred.lasso>cutoff.lasso,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step <- factor(ifelse(pred.step>cutoff.step,">50K","<=50K"),levels=c("<=50K",">50K"))
#Confusion Matrix for Lasso
conf.lasso <- table(class.lasso, test$Income)
print("Confusion matrix for LASSO")
conf.lasso
conf.step<-table(class.step,test$Income)
print("Confusion matrix for Stepwise")
conf.step
#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step <- sum(diag(conf.step))/sum(conf.step)
print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step
# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step <- sensitivity(conf.step)
# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step <- specificity(conf.step)
results.lasso <- prediction(pred.lasso, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso <- performance(results.lasso, measure = "tpr", x.measure = "fpr")
results.step <- prediction(pred.step, test$Income, label.ordering=c("<=50K",">50K"))
roc.step <- performance(results.step, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(roc.lasso, col = "red")
plot(roc.step,col="green", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise"),
col=c("black","green"),lty=1,lwd=1)
abline(a=0, b= 1)
# generate AUC values
auc.lasso <- performance(results.lasso, measure = "auc")
auc.step <- performance(results.step, measure = "auc")
auc.lasso@y.values[[1]]
auc.step@y.values[[1]]
# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso, cutoff.step)
sens <- c(sens.lasso, sens.step)
spec <- c(spec.lasso, spec.step)
acc <- c(acc.lasso, acc.step)
auc <- c(auc.lasso@y.values[[1]], auc.step@y.values[[1]])
testResults <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults) <- c("LASSO", "Stepwise")
#write.csv(testResults, "testResults.csv")
testResults
mod.step2 <- glm(Income~age + flnwgt + education +
marital.status + occupation + relationship +
race + sex + hours.per.week + native.country +
capgain + caploss, data=train, family = "binomial")
mod.step2 <- glm(Income~age + fnlnwgt + education +
marital.status + occupation + relationship +
race + sex + hours.per.week + native.country +
capgain + caploss, data=train, family = "binomial")
mod.step2 <- glm(Income~age + fnlwgt + education +
marital.status + occupation + relationship +
race + sex + hours.per.week + native.country +
capgain + caploss, data=train, family = "binomial")
pred.step2 <- predict(mod.step2, newdata = test, type = "response")
summary(mod.step2)
car::vif(mod.step2)
exp(cbind("Odds ratio" = coef(mod.step), confint.default(mod.step, level = 0.95)))
par(mfrow=c(2,2))
plot(mod.step)
#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step <- sum(diag(conf.step))/sum(conf.step)
acc.step2 <- sum(diag(conf.step2))/sum(conf.step2)
print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step
acc.step2
# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step <- sensitivity(conf.step)
sens.step2 <- sensitivity(conf.step2)
# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step <- specificity(conf.step)
spec.step2 <- specificity(conf.step2)
#Lets use the predicted probabilities to classify the observations and make a final confusion matrix for the two models.  We can use it to calculate error metrics.
#Lets use a cutoff of 0.7 to make the classification.
# factor level order (0,1) = (<=50K, >50K)
cutoff.lasso <- 0.265
cutoff.step <- 0.265
cutoff.step2 <- 0.265
class.lasso <- factor(ifelse(pred.lasso>cutoff.lasso,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step <- factor(ifelse(pred.step>cutoff.step,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step2 <- factor(ifelse(pred.step2>cutoff.step2,">50K","<=50K"),levels=c("<=50K",">50K"))
#Confusion Matrix for Lasso
conf.lasso <- table(class.lasso, test$Income)
print("Confusion matrix for LASSO")
conf.lasso
conf.step<-table(class.step,test$Income)
print("Confusion matrix for Stepwise")
conf.step
conf.step2<-table(class.step2,test$Income)
print("Confusion matrix for Stepwise")
conf.step2
#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step <- sum(diag(conf.step))/sum(conf.step)
acc.step2 <- sum(diag(conf.step2))/sum(conf.step2)
print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step
acc.step2
# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step <- sensitivity(conf.step)
sens.step2 <- sensitivity(conf.step2)
# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step <- specificity(conf.step)
spec.step2 <- specificity(conf.step2)
results.lasso <- prediction(pred.lasso, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso <- performance(results.lasso, measure = "tpr", x.measure = "fpr")
results.step <- prediction(pred.step, test$Income, label.ordering=c("<=50K",">50K"))
roc.step <- performance(results.step, measure = "tpr", x.measure = "fpr")
results.step2 <- prediction(pred.step2, test$Income, label.ordering=c("<=50K",">50K"))
roc.step2 <- performance(results.step2, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(roc.lasso, col = "red")
plot(roc.step,col="green", add = TRUE)
plot(roc.step2, col="orange", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise", "Stepwise w/o workclass"),
col=c("red","green", "orange"),lty=1,lwd=1)
abline(a=0, b= 1)
# generate AUC values
auc.lasso <- performance(results.lasso, measure = "auc")
auc.step <- performance(results.step, measure = "auc")
auc.step2 <- performance(results.step, measure = "auc")
auc.lasso@y.values[[1]]
auc.step@y.values[[1]]
auc.step2@y.values[[1]]
# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso, cutoff.step, cutoff.step2)
sens <- c(sens.lasso, sens.step, sens.step2)
spec <- c(spec.lasso, spec.step, spec.step2)
acc <- c(acc.lasso, acc.step, acc.step2)
auc <- c(auc.lasso@y.values[[1]], auc.step@y.values[[1]], auc.step2@y.values[[1]])
testResults <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults) <- c("LASSO", "Stepwise", "Stepwise w/o workclass")
#write.csv(testResults, "testResults.csv")
testResults
summary(mod.step2)
exp(cbind("Odds ratio" = coef(mod.step), confint.default(mod.step, level = 0.95)))
exp(cbind("Odds ratio" = coef(mod.step2), confint.default(mod.step, level = 0.95)))
exp(cbind("Odds ratio" = coef(mod.step2), confint.default(mod.step2, level = 0.95)))
#Lets use the predicted probabilities to classify the observations and make a final confusion matrix for the two models.  We can use it to calculate error metrics.
#Lets use a cutoff of 0.7 to make the classification.
# factor level order (0,1) = (<=50K, >50K)
cutoff.lasso <- 0.265
cutoff.step <- 0.265
cutoff.step2 <- 0.265
class.lasso <- factor(ifelse(pred.lasso>cutoff.lasso,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step <- factor(ifelse(pred.step>cutoff.step,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step2 <- factor(ifelse(pred.step2>cutoff.step2,">50K","<=50K"),levels=c("<=50K",">50K"))
#Confusion Matrix for Lasso
conf.lasso <- table(class.lasso, test$Income)
print("Confusion matrix for LASSO")
conf.lasso
conf.step<-table(class.step,test$Income)
print("Confusion matrix for Stepwise")
conf.step
conf.step2<-table(class.step2,test$Income)
print("Confusion matrix for Stepwise")
conf.step2
conf.lasso <- table(class.lasso, test$Income)
print("Confusion matrix for LASSO w/o workclass")
conf.lasso
conf.step2<-table(class.step2,test$Income)
print("Confusion matrix for Stepwise w/o workclass")
conf.step2
#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step2 <- sum(diag(conf.step2))/sum(conf.step2)
print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step2
# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step2 <- sensitivity(conf.step2)
# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step2 <- specificity(conf.step2)
#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step <- sum(diag(conf.step))/sum(conf.step)
acc.step2 <- sum(diag(conf.step2))/sum(conf.step2)
print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step
acc.step2
# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step <- sensitivity(conf.step)
sens.step2 <- sensitivity(conf.step2)
# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step <- specificity(conf.step)
spec.step2 <- specificity(conf.step2)
results.lasso <- prediction(pred.lasso, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso <- performance(results.lasso, measure = "tpr", x.measure = "fpr")
results.step <- prediction(pred.step, test$Income, label.ordering=c("<=50K",">50K"))
roc.step <- performance(results.step, measure = "tpr", x.measure = "fpr")
results.step2 <- prediction(pred.step2, test$Income, label.ordering=c("<=50K",">50K"))
roc.step2 <- performance(results.step2, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(roc.lasso, col = "red")
plot(roc.step,col="green", add = TRUE)
plot(roc.step2, col="orange", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise", "Stepwise w/o workclass"),
col=c("red","green", "orange"),lty=1,lwd=1)
abline(a=0, b= 1)
# generate AUC values
auc.lasso <- performance(results.lasso, measure = "auc")
auc.step <- performance(results.step, measure = "auc")
auc.step2 <- performance(results.step, measure = "auc")
auc.lasso@y.values[[1]]
auc.step@y.values[[1]]
auc.step2@y.values[[1]]
# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso, cutoff.step, cutoff.step2)
sens <- c(sens.lasso, sens.step, sens.step2)
spec <- c(spec.lasso, spec.step, spec.step2)
acc <- c(acc.lasso, acc.step, acc.step2)
auc <- c(auc.lasso@y.values[[1]], auc.step@y.values[[1]], auc.step2@y.values[[1]])
testResults <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults) <- c("LASSO", "Stepwise", "Stepwise w/o workclass")
#write.csv(testResults, "testResults.csv")
testResults
cutoff.lda.qda <- c(cutoff.lasso, cutoff.step2, cutoff.lasso.complex, cutoff.lda, cutoff.lda.pca, cutoff.qda.pca)
t(t(workclassTable))
table(train$Income)
t(table(train$Income))
t(aggregate(train$Income))
prop.table(table(train$Income))
results.lasso <- prediction(pred.lasso, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso <- performance(results.lasso, measure = "tpr", x.measure = "fpr")
results.step <- prediction(pred.step, test$Income, label.ordering=c("<=50K",">50K"))
roc.step <- performance(results.step, measure = "tpr", x.measure = "fpr")
results.step2 <- prediction(pred.step2, test$Income, label.ordering=c("<=50K",">50K"))
roc.step2 <- performance(results.step2, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(roc.lasso, col = "red")
plot(roc.step2, col="green", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise"),
col=c("red","green"),lty=1,lwd=1)
abline(a=0, b= 1)
# generate AUC values
auc.lasso <- performance(results.lasso, measure = "auc")
auc.step <- performance(results.step, measure = "auc")
auc.step2 <- performance(results.step, measure = "auc")
auc.lasso@y.values[[1]]
auc.step@y.values[[1]]
auc.step2@y.values[[1]]
