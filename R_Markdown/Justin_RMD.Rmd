---
title: "Project2"
author: "Justin Ehly, Allen Miller, Alex Gilbert "
date: "3/24/2021"
output: html_document
---

```{r libraries}
# Import Libraries
library(tidyverse)
library(stringr)
library(magrittr)
library(car)
library(stats)
library(naniar)
library(GGally)
library(ggplot2)
library(directlabels)
library(caret)
library(glmnet)
library(MASS)
library(caret)
library(ROCR)
library(dplyr)
library(Lahman)
```


```{r data import}
#setwd("C:/Users/justi/Documents/GitHub/6372---50k-Income-Predictor/Data")
#adult_info <- read.csv("adult.data.csv", header = TRUE)
#adult_test <- read.csv("adult.test.csv", header = TRUE)

#Code Path for Allen's MAC
adult_info <- read.csv("/Users/allenmiller/Documents/GitHub/6372---50k-Income-Predictor/Data/adult.data.csv", header = TRUE)
# View(adult_info)
adult_test <- read.csv("/Users/allenmiller/Documents/GitHub/6372---50k-Income-Predictor/Data/adult.test.csv")
# set the clean set to the larger data set

# merge the data + test data to form one dataset for cleaning
tot_adult_info <- rbind(adult_info, adult_test)
str(tot_adult_info)
summary(tot_adult_info)

```

```{r initial data clean inc capital.gain/loss}
clean <- tot_adult_info

#Looking for Null Values - based on data description, NA = "?" or " ?"
sapply(clean, function(x) sum(sum(is.na(x)),
                              sum(x %in% "?"),
                              sum(x %in% " ?"))) 
# quite a few NA's
# workclass = 1836
# occupation = 1843
# native.country = 583

str(clean)
# looking at just the missing values
#missing <- clean %>% filter(occupation %in% " ?" |
#                              workclass %in% " ?" |
#                              native.country %in% " ?")
# View(missing)
# appears all the missing values for workclass are also missing for workclass - 
# let's set to "unknown and see if we can still predict

# replace " ?" with "Unknown"
clean$workclass <- replace(clean$workclass, clean$workclass %in% " ?", "Unknown")
clean$occupation <- replace(clean$occupation, clean$occupation %in% " ?", "Unknown")
clean$native.country <- replace(clean$native.country, clean$native.country %in% " ?", "Unknown")

#convert all chr to factors
clean[sapply(clean, is.character)] <- lapply(clean[sapply(clean, is.character)], as.factor)


levels(clean$workclass)
levels(clean$occupation)
levels(clean$native.country)
clean <- clean[,c(15,1:14)]

str(clean)
# something going on with class - will revisit shortly

summary(clean)
# data set will need to be balanced before any tests run
# 24,720 <=50k vs 7,841 >50k

#output sumamry to csv for easier use in the paper
#write.csv(summary(clean),"data_summary.csv")


# lots of zeros in the capital gains and losses columns, may be better to treat those as yes/no
zeros <- sapply(clean, function(x) sum(x == 0))
gainZeroPerc <- zeros[11]/dim(clean)[1]
gainZeroPerc # ~92% are 0's
lossZeroPerc <- zeros[12]/dim(clean)[1]
lossZeroPerc # ~95% are 0's

clean <- clean %>% mutate(capgain = case_when(capital.gain > 0 ~ "yes",
                                              TRUE ~ "no"),
                          caploss = case_when(capital.loss > 0 ~ "yes",
                                              TRUE ~ "no"))
# convert new columns to factor
clean[sapply(clean, is.character)] <- lapply(clean[sapply(clean, is.character)], as.factor)
str(clean)

# remove leading whitepsace from factors
factorCols <- names(clean)[vapply(clean, is.factor, logical(1))]
clean[,factorCols] <- lapply(clean[,factorCols], trimws)
clean[sapply(clean, is.character)] <- lapply(clean[sapply(clean, is.character)], as.factor)
str(clean)


# remove original capitcal gain/ loss cols
clean <- clean[,-c(12,13)]
names(clean)[1] <- "Income"

levels(clean$Income)
clean$Income <- as.factor(case_when(
  as.character(clean$Income) %in% c(">50K.", " >50K") ~ ">50K",
  as.character(clean$Income) %in% c("<=50K.", " <=50K") ~ "<=50K",
  TRUE ~ as.character(clean$Income)
))
# now the Income column is back to 2 levels


```



```{r clean workclass}
# ---- clean workclass --- #

workclassTable <- table(clean$workclass)
t(t(workclassTable))
propt <- t(t(prop.table(workclassTable)))
colnames(propt) <- "workclass proportions"
propt
p <- prop.table(table(clean$workclass, clean$Income))
p
t(aggregate(workclass~Income,data=clean,summary))
summary(clean$workclass)

# Private have the bulk of the entries ~ 70%
# unpaid people make up less than .001% 
sum(p[c(1,2,7)])*100 # = 13% # gov workers
# all government workers make up a combined 13% maybe we should combine those???
# self employed combined make up 10% 3% inc, 7% not-inc
# this variable may be useful as well - self employed are favored to make >50k
wc <- glm(Income~workclass, clean, family='binomial')
summary(wc)
confint(wc)
# never worked, without-pay arent stat sig, let's combine them now
clean$workclass <- as.factor(case_when(
  as.character(clean$workclass) %in% c("Never-worked", "Without-pay") ~ "Unpaid",
  TRUE ~ as.character(clean$workclass)
))
# unpaid still not sig, so lets merge it with unknown
# also looking over proportions table, we can merge the government jobs together
clean$workclass <- as.factor(case_when(
  as.character(clean$workclass) %in% c("Unknown", "Unpaid") ~ "Unknown/Unpaid",
  as.character(clean$workclass) %in% c("Local-gov", "State-gov", "Federal-gov") ~ "Gov't",
  TRUE ~ as.character(clean$workclass)
))
# rerun our tables
workclassTable <- table(clean$workclass)
propt <- t(t(prop.table(workclassTable)))
colnames(propt) <- "workclass proportions"
propt
p <- prop.table(table(clean$workclass, clean$Income))
p
t(aggregate(workclass~Income,data=clean,summary))
wc <- glm(Income~workclass, clean, family='binomial')
summary(wc)
confint(wc)
# this looks a lot better

```



```{r clean occupation}

as.data.frame(table(clean$occupation))
# armed forces with 15 entries is tiny compared to all the rest, let's look at how we can make it more practical

p.occ <- prop.table(table(clean$occupation, clean$Income))
data.frame(format(p.occ, scientific = FALSE))


occ.glm <- glm(Income~occupation, data=clean, family='binomial')
summary(occ.glm)
confint(occ.glm)
# Occupation, reviewing the breakdown of how many observations are within each factor level of occupation, Armed
# Services represents just 15 of the 48,842 observations or 0.03% of the total, essentially giving it very little
# predictive power, but after a logistic regression test we see the pvalue = 0.03 from zvalue, we notice the 
# confidence interval (-0.02031461,  2.185816489) crosses zero, so merging it with a similar occupation makes 
# sense. Also notable is that Machine-op-inspct has pvalue=0.07 with CI(-0.25527485,  0.009908866).
# AF merge with Protective-serv
# Mach-op-ins merge with Other-Service since they are both primarily in the private sector

clean$occupation <- as.factor(case_when(
  as.character(clean$occupation) %in% c("Armed-Forces", "Protective-serv") ~ "ArmForc/ProtSvc",
  as.character(clean$occupation) %in% c("Machine-op-inspct", "Other-service") ~ "MachOpIns/OthSvc",
  TRUE ~ as.character(clean$occupation)
))
# rerun glm 
occ.glm <- glm(Income~occupation, data=clean, family='binomial')
summary(occ.glm)
confint(occ.glm)

# all pvalues look stat sig, no CI cross zero!

```



```{r clean marital.status}

ms.prop <- prop.table(table(clean$marital.status))
data.frame(ms.prop)

ms.glm <- glm(Income~marital.status, data=clean, family = "binomial")
summary(ms.glm)

# this shows that married-spouse-absent is not stat sig. when divorced is the reference, seems that 
# class fits more with separated than divorced, although that just a legal difference to some people
# that yileded some bad results, going to merge spouse abs with separated


clean$marital.status <- as.factor(case_when(
  as.character(clean$marital.status) %in% c("Married-AF-spouse", 
                        "Married-civ-spouse") ~ "Married-spouse",
  as.character(clean$marital.status) %in% c("Separated", "Married-spouse-absent") ~ "SpsAbs/Separtd",
  TRUE ~ as.character(clean$marital.status)))

levels(clean$marital.status)

ms.glm <- glm(Income~marital.status, data=clean, family = "binomial")
summary(ms.glm)
# this looks better, the other way had widowed looking very bad, still on the borderline
confint(ms.glm)
# ok, looks good now


```



```{r data clean last summary}

summary(clean)

# looks good

```

# EDA ####################################################################

```{r EDA numeric variables}


# check out the int variables
clean %>% select_if(is.integer) %>% 
  ggpairs(ggplot2::aes(color=clean$Income))
# not very good stories here, dont see any dependencies between the numerical values
clean.int <- clean %>% select_if(is.integer) 
cor(clean.int) #stats correlation matrix

library(corpcor)
cor2pcor(cov(clean.int)) # corpcor correlation matrix
# confirmed, no correlation between the continuous variables
```


```{r PCA}

clean.pca <- clean %>% select_if(~class(.) == "integer")
pc.result<-prcomp(clean.pca,scale.=TRUE)
pc.scores<-data.frame(pc.result$x)
pairs(pc.scores[,1:4])
cor(pc.scores)

# scree plot
par(mfrow=c(1,2))
eigenvals<-(pc.result$sdev)^2
plot(1:4,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:4,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
par(mfrow=c(1,1))

#Screen Plot suggests we use 2 PCs - However this doesn't even explain 60% of the variability in the data
#Judging by the variance plot we should use ether 3 (75%) or 4 (99%) PCs

#Add PCs to Clean Data Frame
clean$PC1 <- pc.scores$PC1
clean$PC2 <- pc.scores$PC2
clean$PC3 <- pc.scores$PC3
clean$PC4 <- pc.scores$PC4
str(clean)

```


```{r test for multicollinearity}

fac.clean <- clean %>% select_if(~class(.) == "factor")
fac.clean.glm <- glm(Income~., data=fac.clean, family="binomial")
summary(fac.clean.glm)
vif(fac.clean.glm)
# based on the GVIF^1/(2*Df)) we don't show any multicollinearity among the categorical variables

# During EDA we will look deeper into variables that are continuous and categorical and whether they max_height
# be telling the same story


```


```{r age EDA}
#--- age ---#
t(aggregate(age~Income,data=clean,summary))
# Min Age <=50: 17/ >50: 19 
# Mean Age <=50: 37/ >50: 44
# Max Age = 90 for both
# people making >50 tend to be older, about 7yrs on average

ggplot(clean, aes(age, fill= Income)) + geom_bar(position="fill") +
  scale_x_continuous(breaks=seq(0,90, by = 10)) +
  labs(title="Age by Income") +
  theme_classic()
# quite a big of overlap between <=50 and >50 - may not be a good selector


ggplot(clean, aes(age, fill= Income)) + geom_boxplot() +
  scale_x_continuous(breaks=seq(0,90, by = 10)) + coord_flip() +
  labs(title="Age by Income") +
  theme_classic()
# quite a big of overlap between <=50 and >50 - may not be a good selector

``` 


```{r finlwgt EDA}

ggplot(clean, aes(fnlwgt, fill= Income)) + geom_boxplot() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="FinalWeight by Income",
       x ="Final Weight") + theme_classic() +
  coord_flip()
# this is a weighting metric, so not surprised that they boxplots are about the same
wgt <- glm(Income~fnlwgt, clean, family="binomial")
summary(wgt)
confint(wgt)
# with p-value = 0.08 we show that this variable is not statistically significant in 
# determining Income and a CI that includes 0!
```


```{r workclass EDA}

# --- workclass EDA ---#
# summary tables
prop.table(table(clean$workclass))
aggregate(Income~workclass,data=clean,summary)
prop.table(table(clean$workclass, clean$Income))



ggplot(clean, aes(workclass, fill= Income)) + 
  geom_bar() +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title = "WorkClass by Income") 

ggplot(clean, aes(workclass, fill= Income)) + 
  geom_bar(position="fill") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title = "WorkClass by Income") 

summary(clean$workclass)
```


```{r occupation EDA}


t(aggregate(occupation~workclass,data=clean,summary))
(prop.table(table(clean$workclass, clean$occupation, clean$Income)))

# seems similar to workclass
ggplot(clean, aes(x=workclass, fill= occupation)) + 
  geom_bar() +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Workclass Totals Divided into Occupations")

# just plot occupation totals
ggplot(clean, aes(x=occupation, fill = workclass)) + 
  geom_bar() +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Occupation Totals Broken Out by Workclass")

# pay proportions by occupation
ggplot(clean, aes(x=occupation, fill = Income)) + 
  geom_bar(position = "fill") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Pay Proportions by Occupation")

# Exec-managerial, Prof-sepcialty look good for making >50

```


```{r education and education.num EDA}
#--- education ---#
t(aggregate(education~Income,data=clean,summary))
ggplot(clean, aes(education, fill= Income)) + geom_bar(position="fill") +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Education by Income")
# this one favors more educated people to make >50k

#--- education.num---#
t(aggregate(education.num~Income,data=clean,summary))
# this may work better with education.num as a factor, but more education = more $$$

ggplot(clean, aes(education.num, fill= Income)) + geom_bar(position="fill") +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Education Years by Income") + theme_classic()
# somewhat redundant with education, just in a continuous format

ggplot(clean, aes(education.num, fill= education)) + geom_bar(position="fill") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Education Years broken out by Education Level")
# somewhat redundant with education, just in a continuous format
# we can let the software decide which one works best in modeling

table(clean$education.num, clean$education)

prop.table(table(clean$education.num, clean$education))

# confirmed, these variables are telling us the same thing in terms of income vs edcation.


```


```{r marital.status and relationship EDA}
t(aggregate(marital.status~Income,data=clean,summary))
# married people have the better chances of earning >50k
ggplot(clean, aes(x=marital.status, fill= Income)) + 
  geom_bar(position="fill") +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Marital Status by Income")
# Married-AF-spouse (armed forces) and Married-civ-spouse (civilian) have highest potential to make >50k 
#--- combining married-AF with married-civ since there are only 23 married-AF


# married people have the better chances of earning >50k

t(aggregate(relationship~Income,data=clean,summary))
ggplot(clean, aes(relationship, fill= Income)) + geom_bar(position="fill") +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Relationship by Income") + theme_classic()
# redunant to marital.status where married people have highest potential to >50

t(aggregate(marital.status~relationship,data=clean,summary))
ggplot(clean, aes(x=relationship, fill= marital.status)) + 
  geom_bar(stat="count") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Relationship by Marital Status")

t(aggregate(marital.status~sex+Income,data=clean,summary))
ggplot(clean, aes(relationship, fill= Income)) + geom_bar(position="fill") +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Relationship by Income") + theme_classic()
# redunant to marital.status where married people have highest potential to >50

tb <- table(clean$marital.status, clean$relationship)
tb
prop.table(tb)

```


```{r race, native country EDA}
t(aggregate(race~Income,data=clean,summary))

# reorder by proportion of race to >50K
clean %>% mutate(race = forcats::fct_reorder(.f = race,
                                                 .x = Income,
                                                 .fun = function(.x) mean (.x == ">50K"),
                                                 .desc = TRUE)) %>% 
ggplot(aes(race, fill= Income)) + geom_bar(position="fill") +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Race by Income") + theme_classic()
# none of these seems to point to making over 50

t(aggregate(native.country~Income,data=clean,summary))

clean %>% mutate(native.country = forcats::fct_reorder(.f = native.country,
                                                 .x = Income,
                                                 .fun = function(.x) mean (.x == ">50K"),
                                                 .desc = TRUE)) %>% 
  ggplot(aes(x= native.country, fill= Income)) + 
  geom_bar(position="fill") +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Native Country by Income Proportion")
# quite a few of these pop, may be very useful

```
 
 
```{r capgain/ caploss EDA}
t(aggregate(capgain~Income,data=clean,summary))
prop.table(table(clean$capgain,clean$Income))

ggplot(clean, aes(capgain, fill= Income)) + geom_bar(position="fill") +
  labs(title="Has Capital Gains by Income") + theme_classic()
  #theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0))
# people with capital gains tend to make more than 50

t(aggregate(caploss~Income,data=clean,summary))
prop.table(table(clean$caploss,clean$Income))
ggplot(clean, aes(caploss, fill= Income)) + geom_bar(position="fill") +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  labs(title="Has Capital Loss by Income") + theme_classic()
# people with capital.loss also have tend to make >50

```


```{r hours/week EDA}
t(aggregate(hours.per.week~Income,data=clean,summary))
prop.table(table(clean$hours.per.week, clean$Income))

clean %>%
ggplot(aes(hours.per.week, fill= Income)) + 
  geom_bar(position="fill") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  scale_x_continuous(breaks=seq(0,100, by = 10)) +
  labs(title="Hours Per Week by Income",
       x = "Hours Worked Per Week",
       y = "Proportions") 

# this maybe a decent predictor since we can see some separation between hours and over/under 50k

ggplot(clean, aes(x=occupation,y=hours.per.week, fill= Income)) + geom_bar(stat="identity") +
  theme(axis.text.x = element_text(angle = 270, vjust = 0, hjust = 0)) +
  scale_y_continuous(breaks=seq(0,100, by = 10)) +
  labs(title="Hours Per Week by Income",
       x = "Occupation",
       y = "Hours/Week") 


```

# ----- Split train/ test ----- #

```{r split clean df into train/ test 2/3 vs 1/3}

holder <- clean

set.seed(123)

# establish the orde of the Income factor levels
smp.size <- floor( (nrow(clean)/3) * 2)
train.ind <- sample(seq_len(nrow(clean)), size=smp.size)
train <- clean[train.ind,]
test <- clean[-train.ind,]

prop.table(table(train$Income))
# ~76% <=50K
# ~ 24% >50K


```


# # ----- Models ----- #

```{r LASSO - Regression}


dat.train.x <- model.matrix(Income~.,train)[,-1]
dat.train.y<-train$Income
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")
#CV misclassification error rate is little below .1
print("CV Error Rate:")
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]

#Optimal penalty
print("Penalty Value:")
cvfit$lambda.min

#For final model predictions go ahead and refit lasso using entire
#data set
finalmodel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)
# LASSO chose : age, workclass, fnlwgt, education, marital.status, occupation, relationship, race, 
# hours.per.week, native.country, capgain, caploss
```


```{r LR model from LASSO}
mod.lasso <- glm(Income~age + workclass + fnlwgt + education +
              marital.status + occupation + relationship +
              race + hours.per.week + native.country + capgain + caploss,
            data=train, family = "binomial")
pred.lasso <- predict(mod.lasso, newdata = test, type = "response")

summary(mod.lasso)
# confint(mod.lasso)
car::vif(mod.lasso)

exp(cbind("Odds ratio" = coef(mod.lasso), confint.default(mod.lasso, level = 0.95)))

par(mfrow=c(2,2))
plot(mod.lasso)
```



```{r stepwise}
# using the MASS package

mod.full <- glm(Income~., data=train, family = "binomial")
mod.step <- mod.full %>% stepAIC(trace=FALSE)
pred.step <- predict(mod.step, newdata = test, type = "response")


summary(mod.step)
# confint(mod.step)
car::vif(mod.step)

exp(cbind("Odds ratio" = coef(mod.step), confint.default(mod.step, level = 0.95)))

par(mfrow=c(2,2))
plot(mod.step)
```


```{r confusion matrix}

#Lets use the predicted probabilities to classify the observations and make a final confusion matrix for the two models.  We can use it to calculate error metrics.
#Lets use a cutoff of 0.7 to make the classification.
# factor level order (0,1) = (<=50K, >50K)
cutoff.lasso <- 0.7
cutoff.step <- 0.7
class.lasso <- factor(ifelse(pred.lasso>cutoff.lasso,">50K","<=50K"),levels=c("<=50K",">50K"))
class.step <- factor(ifelse(pred.step>cutoff.step,">50K","<=50K"),levels=c("<=50K",">50K"))

#Confusion Matrix for Lasso
conf.lasso <- table(class.lasso, test$Income)
print("Confusion matrix for LASSO")
conf.lasso

conf.step<-table(class.step,test$Income)
print("Confusion matrix for Stepwise")
conf.step

```

```{r accuracy tests}

#Accuracy of LASSO and Stepwise
acc.lasso <- sum(diag(conf.lasso))/sum(conf.lasso)
acc.step <- sum(diag(conf.step))/sum(conf.step)

print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso
acc.step

# sensitivity A/(A+C)
sens.lasso <- sensitivity(conf.lasso)
sens.step <- sensitivity(conf.step)

# specificity D/(B+D)
spec.lasso <- specificity(conf.lasso)
spec.step <- specificity(conf.step)

```


```{r roc curves}

results.lasso <- prediction(pred.lasso, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso <- performance(results.lasso, measure = "tpr", x.measure = "fpr")


results.step <- prediction(pred.step, test$Income, label.ordering=c("<=50K",">50K"))
roc.step <- performance(results.step, measure = "tpr", x.measure = "fpr")

par(mfrow=c(1,1))

plot(roc.lasso, col = "red")
plot(roc.step,col="green", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise"),
       col=c("black","green"),lty=1,lwd=1)
abline(a=0, b= 1)

# generate AUC values
auc.lasso <- performance(results.lasso, measure = "auc")
auc.step <- performance(results.step, measure = "auc")
auc.lasso@y.values[[1]]
auc.step@y.values[[1]]


  
```


```{r Table For Part 1 Results}

# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso, cutoff.step)
sens <- c(sens.lasso, sens.step)
spec <- c(spec.lasso, spec.step)
acc <- c(acc.lasso, acc.step)
auc <- c(auc.lasso@y.values[[1]], auc.step@y.values[[1]])

testResults <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults) <- c("LASSO", "Stepwise")
testResults

```
```{r Look for Interaction}
#testing p-values for interaction between variables we thought may interact in EDA
chisq.test(train$race, train$age)
chisq.test(train$occupation, train$age)
chisq.test(train$education.num, train$occupation)
chisq.test(train$age, train$marital.status)
chisq.test(train$age, train$education)
chisq.test(train$marital.status, train$education)


#Plots to see interaction
train %>% ggplot(aes(x = age, y = education, color = Income)) + geom_boxplot()
train %>% ggplot(aes(x = age, y = marital.status, color = Income)) + geom_boxplot()
train %>% ggplot(aes(x = age, y = relationship, color = Income)) + geom_boxplot()
train %>% ggplot(aes(x = relationship, y = marital.status, color = Income)) + geom_jitter()
train %>% ggplot(aes(x = marital.status, y = education, color = Income)) + geom_jitter()

```

```{r More Complex Logistic Model}
# LASSO chose : age, workclass, fnlwgt, education, marital.status, occupation, relationship, race, 
# hours.per.week, native.country, capgain, caploss
#added age*marital.status, age*education, marital.status*education

mod.lasso.complex <- glm(Income~age + workclass + fnlwgt + education +
              marital.status + occupation + relationship +
              race + hours.per.week + native.country + capgain + caploss  + I(age^2) + I(age^3) + I(age^4) + I(age^5) + I(age^6),
            data=train, family = "binomial")
pred.lasso.complex <- predict(mod.lasso.complex, newdata = test, type = "response")

summary(mod.lasso.complex)
# confint(mod.lasso)
#car::vif(mod.lasso.complex)

exp(cbind("Odds ratio" = coef(mod.lasso.complex), confint.default(mod.lasso.complex, level = 0.95)))

par(mfrow=c(2,2))
plot(mod.lasso.complex)



```

```{r Confusion Matrix for Complex}
#Lets use the predicted probabilities to classify the observations and make a final confusion matrix for the two models.  We can use it to calculate error metrics.
#Lets use a cutoff of 0.5 to make the classification.
# factor level order (0,1) = (<=50K, >50K)
cutoff.lasso.complex <- 0.5
class.lasso.complex <- factor(ifelse(pred.lasso.complex>cutoff.lasso.complex,">50K","<=50K"),levels=c("<=50K",">50K"))

#Confusion Matrix for Lasso
conf.lasso.complex <- table(class.lasso.complex, test$Income)
print("Confusion matrix for LASSO.Complex")
conf.lasso.complex
```

```{r accuracy tests}

#Accuracy of complex
acc.lasso.complex <- sum(diag(conf.lasso.complex))/sum(conf.lasso.complex)

print("Overall accuracy for LASSO and Stepwise respectively")
acc.lasso.complex

# sensitivity A/(A+C)
sens.lasso.complex <- sensitivity(conf.lasso.complex)

# specificity D/(B+D)
spec.lasso.complex <- specificity(conf.lasso.complex)

```

```{r roc curves}

results.lasso.complex <- prediction(pred.lasso.complex, test$Income, label.ordering=c("<=50K",">50K"))
roc.lasso.complex <- performance(results.lasso.complex, measure = "tpr", x.measure = "fpr")


par(mfrow=c(1,1))

plot(roc.lasso.complex, col = "red")

# generate AUC values
auc.lasso.complex <- performance(results.lasso.complex, measure = "auc")
auc.lasso.complex@y.values[[1]]


  
```

```{r Table For Complex LASSO Results}

# Table for Accuracy, Sensitivity, Specificity
cutoff <- c(cutoff.lasso.complex)
sens <- c(sens.lasso.complex)
spec <- c(spec.lasso.complex)
acc <- c(acc.lasso.complex)
auc <- c(auc.lasso.complex@y.values[[1]])

testResults.complex <- data.frame(cutoff, sens, spec, acc, auc)
names(testResults.complex) <- c("Cutoff", "Sensitivity", "Specificity", "Accuracy", "AUC")
rownames(testResults.complex) <- c("LASSO.Complex")
testResults.complex

```


```{r Constructing LDA Model Non-PCA}
# construct the LDA model
#age, fnlwgt, education.num, hours.per.week
mylda <- lda(Income ~ age + fnlwgt + education.num + hours.per.week, data = train)

pred<-predict(mylda,newdata=test)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Income
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/length(test$Income)

# accuracy for LDA
acc.lda <- 1-ME

print("Overall accuracy for LDA")
acc.lda

# sensitivity A/(A+C)
sens.lda <- sensitivity(x)

print("Sensitivity for LDA")
sens.lda

# specificity D/(B+D)
spec.lda <- specificity(x)

print("Specificity for LDA")
spec.lda


#Looks like the Non-PCA LDA model performs worse than our complex LASSO model
#Both Models perform worse than our original LASSO and Stepwise Models
```


```{r Constructing LDA Model PCA}
# construct the LDA Using PCA model

#Chose to use 4 PCs since 3 didn't even explain 80% of the variability in the model.
#If we chose 2 PCs like the screen plot suggested we would only be explaining about 60% of the variability
myldaPCA <- lda(Income ~ PC1 + PC2 + PC3 + PC4, data = train)

pred<-predict(myldaPCA,newdata=test)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Income
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/length(test$Income)

# accuracy of LDA.PCA
acc.lda.pca <- 1-ME

print("Overall accuracy for LDA.PCA")
acc.lda.pca

# sensitivity A/(A+C)
sens.lda.pca <- sensitivity(x)

print("Sensitivity for LDA.PCA")
sens.lda.pca

# specificity D/(B+D)
spec.lda.pca <- specificity(x)

print("Specificity for LDA.PCA")
spec.lda.pca



#Looks like using PCA on LDA to predict Income doesn't perform as well as just LDA or the Complex LASSO model
#All models for Part 2 have performed worse than our original model from Part 1

```

```{r Constructing QDA PCA Model}
# construct the PCA QDA model

#Chose to use 4 PCs since 3 didn't even explain 80% of the variability in the model.
#If we chose 2 PCs like the screen plot suggested we would only be explaining about 60% of the variability
myQda <- qda(Income ~ PC1 + PC2 + PC3, data = train)

pred<-predict(myQda,newdata=test)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Income
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/length(test$Income)

# accuracy of QDA.PCA
acc.qda.pca <- 1-ME

print("Overall accuracy for QDA.PCA")
acc.qda.pca

# sensitivity A/(A+C)
sens.qda.pca <- sensitivity(x)

print("Sensitivity for QDA.PCA")
sens.qda.pca

# specificity D/(B+D)
spec.qda.pca <- specificity(x)

print("Specificity for QDA.PCA")
spec.qda.pca
#Once again, using PCA on a QDA model performed worse than all previous models (though only barely in the case of PCA LDA)
#All models for Part 2 have performed worse than our original model from Part 1

```

```{r Table For LDA / QDA Results}

# Table for Accuracy, Sensitivity, Specificity
sens.lda.qda <- c(sens.lda, sens.lda.pca, sens.qda.pca)
spec.lda.qda <- c(spec.lda, spec.lda.pca, spec.qda.pca)
acc.lda.qda <- c(acc.lda, acc.lda.pca, acc.qda.pca)

testResults.lda <- data.frame(sens.lda.qda, spec.lda.qda, acc.lda.qda)
names(testResults.lda) <- c("Sensitivity", "Specificity", "Accuracy")
rownames(testResults.lda) <- c("LDA", "LDA.PCA", "QDA.PCA")
testResults.lda

```

